import { NextResponse } from "next/server"
import OpenAI from "openai"

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
})

export async function POST(req: Request) {
  try {
    const formData = await req.formData()
    const messages = JSON.parse(formData.get("messages") as string)
    const taskTitle = formData.get("taskTitle") as string
    const file = formData.get("file") as File | null

    let fileRef: string | null = null

    if (file) {
      const arrayBuffer = await file.arrayBuffer()
      const blob = new Blob([arrayBuffer], { type: file.type })

      const upload = await client.files.create({
        file: blob,
        purpose: "assistants",
      })

      fileRef = upload.id
    }

    const completion = await client.responses.create({
      model: "gpt-4o-mini",
      input: [
        {
          role: "system",
          content:
            "B·∫°n l√† tr·ª£ l√Ω AI trong app qu·∫£n l√Ω nhi·ªám v·ª•. H√£y gi·ªØ gi·ªçng th√¢n thi·ªán, ng·∫Øn g·ªçn, th·ª±c t·∫ø v√† gi√∫p ng∆∞·ªùi d√πng hi·ªÉu nhanh n·ªôi dung file ho·∫∑c nhi·ªám v·ª•.",
        },
        ...messages.map((m: any) => ({
          role: m.role,
          content: `${m.role === "user" ? "Ng∆∞·ªùi d√πng" : "AI"}: ${m.content}`,
        })),
        {
          role: "system",
          content: `Nhi·ªám v·ª• hi·ªán t·∫°i: ${taskTitle || "Ch∆∞a c√≥ ti√™u ƒë·ªÅ nhi·ªám v·ª•."}`,
        },
      ],
      ...(fileRef
        ? {
            attachments: [
              {
                file_id: fileRef,
              },
            ],
          }
        : {}),
    })

    const reply =
      completion.output_text || "Xin l·ªói, t√¥i kh√¥ng th·ªÉ ph·∫£n h·ªìi l√∫c n√†y üòÖ"

    return NextResponse.json({ reply })
  } catch (err: any) {
    console.error("‚ùå AI error:", err)
    return NextResponse.json(
      { reply: "L·ªói m√°y ch·ªß ho·∫∑c API üò¢", error: err.message },
      { status: 500 }
    )
  }
}
